{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyi6JX5jWw3E9R5VyN6Ggw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"DffRmK4XA5pS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594792253261,"user_tz":-330,"elapsed":32380,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"5586b5a5-775d-4aff-e94e-e373a61febb4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"32Be4upyBdZX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594792289330,"user_tz":-330,"elapsed":7437,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"6d9d8d64-c69c-4dd5-c216-da16e614a2b6"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HO7nxRIzBwbD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792301926,"user_tz":-330,"elapsed":2836,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","import os\n","import random\n","from scipy import ndarray"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"M15c58hCB0nl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792335319,"user_tz":-330,"elapsed":799,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["# Data Augmentation on jeans"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"lgp1VTs2B9Ou","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792445288,"user_tz":-330,"elapsed":26638,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["from scipy import ndimage, misc\n","import numpy as np\n","import os\n","import cv2\n","\n","def rotate():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Jeans\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/jeans\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_rotate = cv2.imread(input_path)\n","\n","        # rotate the image\n","        img_rotate_90_clockwise = cv2.rotate(image_to_rotate, cv2.ROTATE_90_CLOCKWISE)\n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'rotate_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'rotated_'+image_path)\n","        cv2.imwrite(fullpath, img_rotate_90_clockwise)\n","\n","if __name__ == '__main__':\n","    rotate()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJBacMH3CRzs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792530673,"user_tz":-330,"elapsed":2233,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def resize():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Jeans\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/jeans\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_resize = cv2.imread(input_path)\n","\n","        # resize the image\n","        image_resized = cv2.resize(image_to_resize, (300, 200))\n","\n","        image_rgb = cv2.cvtColor(image_to_resize, cv2.COLOR_BGR2RGB)\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'resize_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'resize_'+image_path)\n","        cv2.imwrite(fullpath, image_resized)\n","\n","if __name__ == '__main__':\n","    resize()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-J0wfifVCsm_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792615278,"user_tz":-330,"elapsed":2117,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def flip():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Jeans\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/jeans\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_flip = cv2.imread(input_path)\n","\n","        # flip the image\n","        img_flip_ud = cv2.flip(image_to_flip, 0)\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'flip_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'flip_'+image_path)\n","        cv2.imwrite(fullpath, img_flip_ud)\n","\n","if __name__ == '__main__':\n","    flip()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"wopeXJ4MDBS-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792838479,"user_tz":-330,"elapsed":2296,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def sharpen():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Jeans\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/jeans\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_sharp = cv2.imread(input_path)\n","\n","        # sharp the image\n","        kernel = np.array([[0, -1, 0], \n","                   [-1, 5,-1], \n","                   [0, -1, 0]])\n","        \n","\n","        # Sharpen image\n","        image_sharp = cv2.filter2D(image_to_sharp, -1, kernel)\n","        \n","        # create full output path, 'example.jpg' \n","        # becomes 'sharp_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'sharp_'+image_path)\n","        cv2.imwrite(fullpath, image_sharp)\n","\n","if __name__ == '__main__':\n","    sharpen()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"OC6SXkQlD3vT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594792955942,"user_tz":-330,"elapsed":1980,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def bright():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Jeans\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/jeans\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_bright = cv2.imread(input_path)\n","\n","        # bright the image\n","        image= cv2.add(image_to_bright,np.array([50.0]))\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'bright_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'bright_'+image_path)\n","        cv2.imwrite(fullpath, image)\n","\n","if __name__ == '__main__':\n","    bright()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"x94JlKBDEUeZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793023079,"user_tz":-330,"elapsed":1993,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["#decreasing brightness\n","def decbright():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Jeans\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/jeans\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_bright = cv2.imread(input_path)\n","\n","        # bright the image\n","        image= cv2.add(image_to_bright,np.array([-50.0]))\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'bright_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'decbright_'+image_path)\n","        cv2.imwrite(fullpath, image)\n","\n","if __name__ == '__main__':\n","    decbright()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwSUpsjWEk2L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793103125,"user_tz":-330,"elapsed":936,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["# Data Augmentation using opencv (sarees)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"1UH3dO8-E4r6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793185594,"user_tz":-330,"elapsed":24452,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def rotate():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Sarees\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/saree\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_rotate = cv2.imread(input_path)\n","\n","        # rotate the image\n","        img_rotate_90_clockwise = cv2.rotate(image_to_rotate, cv2.ROTATE_90_CLOCKWISE)\n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'rotate_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'rotated_'+image_path)\n","        cv2.imwrite(fullpath, img_rotate_90_clockwise)\n","\n","if __name__ == '__main__':\n","    rotate()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSZ8AYCqFHE_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793260508,"user_tz":-330,"elapsed":2112,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def bright():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Sarees\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/saree\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_bright = cv2.imread(input_path)\n","\n","        # bright the image\n","        image= cv2.add(image_to_bright,np.array([50.0]))\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'bright_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'bright_'+image_path)\n","        cv2.imwrite(fullpath, image)\n","\n","if __name__ == '__main__':\n","    bright()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"9DUlTpz6Fe0P","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793329432,"user_tz":-330,"elapsed":2818,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def decbright():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Sarees\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/saree\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_bright = cv2.imread(input_path)\n","\n","        # bright the image\n","        image= cv2.add(image_to_bright,np.array([-50.0]))\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'bright_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'decbright_'+image_path)\n","        cv2.imwrite(fullpath, image)\n","\n","if __name__ == '__main__':\n","    decbright()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7yxAf2EFvea","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793435184,"user_tz":-330,"elapsed":2143,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def flip():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Sarees\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/saree\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_flip = cv2.imread(input_path)\n","\n","        # flip the image\n","        img_flip_ud = cv2.flip(image_to_flip, 0)\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'flip_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'flip_'+image_path)\n","        cv2.imwrite(fullpath, img_flip_ud)\n","\n","if __name__ == '__main__':\n","    flip()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8TN_XqKGJdY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793511196,"user_tz":-330,"elapsed":2297,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def resize():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Sarees\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/saree\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_resize = cv2.imread(input_path)\n","\n","        # resize the image\n","        image_resized = cv2.resize(image_to_resize, (300, 200))\n","\n","        image_rgb = cv2.cvtColor(image_to_resize, cv2.COLOR_BGR2RGB)\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'resize_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'resize_'+image_path)\n","        cv2.imwrite(fullpath, image_resized)\n","\n","if __name__ == '__main__':\n","    resize()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YBh1Du6Gb-2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793589652,"user_tz":-330,"elapsed":2310,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def sharpen():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Sarees\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/saree\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_sharp = cv2.imread(input_path)\n","\n","        # sharp the image\n","        kernel = np.array([[0, -1, 0], \n","                   [-1, 5,-1], \n","                   [0, -1, 0]])\n","        \n","\n","        # Sharpen image\n","        image_sharp = cv2.filter2D(image_to_sharp, -1, kernel)\n","        \n","        # create full output path, 'example.jpg' \n","        # becomes 'sharp_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'sharp_'+image_path)\n","        cv2.imwrite(fullpath, image_sharp)\n","\n","if __name__ == '__main__':\n","    sharpen()"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"in-1B3WQGvG-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594793633467,"user_tz":-330,"elapsed":908,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["# Data Augmentation using opencv (trousers)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSiaA48rG6LF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594797855017,"user_tz":-330,"elapsed":31168,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def rotate():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Trouser\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/trousers\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_rotate = cv2.imread(input_path)\n","\n","        # rotate the image\n","        img_rotate_90_clockwise = cv2.rotate(image_to_rotate, cv2.ROTATE_90_CLOCKWISE)\n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'rotate_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'rotated_'+image_path)\n","        cv2.imwrite(fullpath, img_rotate_90_clockwise)\n","\n","if __name__ == '__main__':\n","    rotate()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7mAv_mxsW5bA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594797936792,"user_tz":-330,"elapsed":2177,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def resize():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Trouser\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/trousers\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_resize = cv2.imread(input_path)\n","\n","        # resize the image\n","        image_resized = cv2.resize(image_to_resize, (300, 200))\n","\n","        image_rgb = cv2.cvtColor(image_to_resize, cv2.COLOR_BGR2RGB)\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'resize_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'resize_'+image_path)\n","        cv2.imwrite(fullpath, image_resized)\n","\n","if __name__ == '__main__':\n","    resize()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDbedCRiXUd9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798010470,"user_tz":-330,"elapsed":2313,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def flip():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Trouser\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/trousers\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_flip = cv2.imread(input_path)\n","\n","        # flip the image\n","        img_flip_ud = cv2.flip(image_to_flip, 0)\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'flip_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'flip_'+image_path)\n","        cv2.imwrite(fullpath, img_flip_ud)\n","\n","if __name__ == '__main__':\n","    flip()"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pE1u-1uXmbY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798083686,"user_tz":-330,"elapsed":2464,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def sharpen():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Trouser\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/trousers\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_sharp = cv2.imread(input_path)\n","\n","        # sharp the image\n","        kernel = np.array([[0, -1, 0], \n","                   [-1, 5,-1], \n","                   [0, -1, 0]])\n","        \n","\n","        # Sharpen image\n","        image_sharp = cv2.filter2D(image_to_sharp, -1, kernel)\n","        \n","        # create full output path, 'example.jpg' \n","        # becomes 'sharp_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'sharp_'+image_path)\n","        cv2.imwrite(fullpath, image_sharp)\n","\n","if __name__ == '__main__':\n","    sharpen()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKp2A6ddX4RO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798178057,"user_tz":-330,"elapsed":2988,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def bright():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Trouser\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/trousers\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_bright = cv2.imread(input_path)\n","\n","        # bright the image\n","        image= cv2.add(image_to_bright,np.array([50.0]))\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'bright_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'bright_'+image_path)\n","        cv2.imwrite(fullpath, image)\n","\n","if __name__ == '__main__':\n","    bright()"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ry1CSIYOYPLg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798247872,"user_tz":-330,"elapsed":1856,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["def decbright():\n","    outPath = \"/content/gdrive/My Drive/Colab Notebooks/Augmented images 2/Trouser\"\n","    path = \"/content/gdrive/My Drive/Colab Notebooks/scrap_img/train/trousers\"\n","\n","    # iterate through the names of contents of the folder\n","    for image_path in os.listdir(path):\n","\n","        # create the full input path and read the file\n","        input_path = os.path.join(path, image_path)\n","        image_to_bright = cv2.imread(input_path)\n","\n","        # bright the image\n","        image= cv2.add(image_to_bright,np.array([-50.0]))\n","        \n","\n","\n","        # create full output path, 'example.jpg' \n","        # becomes 'bright_example.jpg', save the file to disk\n","        fullpath = os.path.join(outPath, 'decbright_'+image_path)\n","        cv2.imwrite(fullpath, image)\n","\n","if __name__ == '__main__':\n","    decbright()"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7uFkIJPYgf9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798295901,"user_tz":-330,"elapsed":938,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["# Building CNN"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpPXojp9YsdL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594798300177,"user_tz":-330,"elapsed":1157,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"ef2cd64a-45a2-42a0-c616-1e035ec239ac"},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import backend as K"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Yf4bPNn7Ytcy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798376406,"user_tz":-330,"elapsed":1181,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["# dimensions of our images.\n","input_shape=(150,150,3)\n","img_width, img_height = 150, 150\n","\n","train_data_dir = '/content/gdrive/My Drive/Colab Notebooks/Augmented images 2'\n","validation_data_dir = '/content/gdrive/My Drive/Colab Notebooks/scrap_img/train'"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4WfHn8WZACb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798395733,"user_tz":-330,"elapsed":950,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["from keras.preprocessing.image import ImageDataGenerator, load_img"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9S5a08DZE0n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594798410391,"user_tz":-330,"elapsed":893,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"5dea022e-3195-4973-b770-960a7954a119"},"source":["#rescaling data\n","datagen=ImageDataGenerator(rescale=1./255)\n","\n","train_generator=datagen.flow_from_directory(\n","         train_data_dir,\n","         target_size=(img_width,img_height),\n","         batch_size=8,\n","         class_mode='categorical')\n","\n","validation_generator=datagen.flow_from_directory(\n","         validation_data_dir,\n","         target_size=(img_width,img_height),\n","         batch_size=16,\n","         class_mode='categorical')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Found 1848 images belonging to 3 classes.\n","Found 308 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WsoYL35eZIaT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798468103,"user_tz":-330,"elapsed":894,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["nb_train_samples=1842\n","nb_validation_samples=500\n","batch_size=32\n","epochs=20"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"445nrM8kZWfd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594798483777,"user_tz":-330,"elapsed":879,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"b6f970c8-ad07-4e36-9199-dceaecaa6deb"},"source":["#model building\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","#flatten layer\n","model.add(Flatten()) # Output convert into one dimension layer and will go to Dense layer\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Dense(3, activation='softmax'))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aNQTIYJfZaVD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":765},"executionInfo":{"status":"ok","timestamp":1594798500356,"user_tz":-330,"elapsed":951,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"1bc414dc-17eb-4426-f1b3-a4db0d783bd0"},"source":["model.summary()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 148, 148, 32)      0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 74, 74, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 72, 72, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 36, 36, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 34, 34, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 18496)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                1183808   \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 64)                0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 65        \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 3)                 6         \n","=================================================================\n","Total params: 1,212,519\n","Trainable params: 1,212,519\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"getXZmQjZeXq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594798523363,"user_tz":-330,"elapsed":982,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}}},"source":["from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint= ModelCheckpoint(\"Model1.h5\", monitor=\"val_loss\",mode='min', save_best_only=True,verbose=1)\n","\n","earlystop= EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=3,verbose=1,restore_best_weights=True)\n","\n","reduce_lr= ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, verbose=1, min_delta=0.0001)\n","\n","#putiing callbacks into callback list\n","callbacks = [earlystop, checkpoint, reduce_lr]\n","\n","#we use a very small learning rate\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer=Adam(learning_rate=0.01),\n","              metrics=['accuracy'])"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Dt6H7PcZj-p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"status":"ok","timestamp":1594798637483,"user_tz":-330,"elapsed":89437,"user":{"displayName":"Sohail Mohd","photoUrl":"","userId":"06787105129744541200"}},"outputId":"5a0313ff-c16e-4db5-b989-418bf69386aa"},"source":["history=model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_samples//batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=nb_validation_samples//batch_size,\n","    callbacks = [earlystop, checkpoint, reduce_lr])"],"execution_count":34,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/20\n","57/57 [==============================] - 18s 319ms/step - loss: 2.5814 - accuracy: 0.3311 - val_loss: 1.1061 - val_accuracy: 0.3167\n","\n","Epoch 00001: val_loss improved from inf to 1.10613, saving model to Model1.h5\n","Epoch 2/20\n","57/57 [==============================] - 17s 305ms/step - loss: 1.0999 - accuracy: 0.3596 - val_loss: 1.0830 - val_accuracy: 0.3640\n","\n","Epoch 00002: val_loss improved from 1.10613 to 1.08302, saving model to Model1.h5\n","Epoch 3/20\n","57/57 [==============================] - 17s 296ms/step - loss: 1.1030 - accuracy: 0.3092 - val_loss: 1.1013 - val_accuracy: 0.3333\n","\n","Epoch 00003: val_loss did not improve from 1.08302\n","Epoch 4/20\n","57/57 [==============================] - 17s 296ms/step - loss: 1.0990 - accuracy: 0.3596 - val_loss: 1.1108 - val_accuracy: 0.3377\n","\n","Epoch 00004: val_loss did not improve from 1.08302\n","Epoch 5/20\n","57/57 [==============================] - 18s 309ms/step - loss: 1.0967 - accuracy: 0.3794 - val_loss: 1.1363 - val_accuracy: 0.3417\n","Restoring model weights from the end of the best epoch\n","\n","Epoch 00005: val_loss did not improve from 1.08302\n","\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PzfjT1wuZqPj","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}